{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda, Dense, Dot, Dropout, Bidirectional, concatenate, Add, Subtract, Flatten, Multiply \n",
    "from keras.layers import MaxPooling1D, AveragePooling1D \n",
    "from keras.regularizers import l2 \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import gensim \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid         search_term  relevance  \\\n",
       "0   2       100001       angle bracket       3.00   \n",
       "1   3       100001           l bracket       2.50   \n",
       "2   9       100002           deck over       3.00   \n",
       "3  16       100005    rain shower head       2.33   \n",
       "4  17       100005  shower only faucet       2.67   \n",
       "\n",
       "                                 product_description  \n",
       "0  Not only do angles make joints stronger, they ...  \n",
       "1  Not only do angles make joints stronger, they ...  \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...  \n",
       "3  Update your bathroom with the Delta Vero Singl...  \n",
       "4  Update your bathroom with the Delta Vero Singl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    product_des = pd.read_csv('./data/product_descriptions.csv/product_descriptions.csv')\n",
    "    train = pd.read_csv('./data/train.csv/train.csv', encoding='ISO-8859-1')\n",
    "    test = pd.read_csv('./data/test.csv.zip', encoding='ISO-8859-1')\n",
    "    #test_sol = pd.read_csv('../input/test-solution-ass4/test_solution_ass4.csv')\n",
    "    #test_sol = test_sol[test_sol['relevance']!=-1]\n",
    "    #test_sol = test_sol.drop(['Usage'], axis=1)\n",
    "    test = test.merge(product_des, on='product_uid', how='left')\n",
    "    test = test.drop(['product_title'], axis=1)\n",
    "    #test = test_sol.merge(test, on='id', how='left')\n",
    "    train = train.merge(product_des, on='product_uid', how='left')\n",
    "    train = train.drop(['product_title'], axis=1)\n",
    "    return train, test\n",
    "\n",
    "train, test = load_data()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>[angle, bracket]</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[Not, only, do, angles, make, joints, stronger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>[l, bracket]</td>\n",
       "      <td>2.50</td>\n",
       "      <td>[Not, only, do, angles, make, joints, stronger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>[deck, over]</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[BEHR, Premium, Textured, DECKOVER, is, an, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>[rain, shower, head]</td>\n",
       "      <td>2.33</td>\n",
       "      <td>[Update, your, bathroom, with, the, Delta, Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>[shower, only, faucet]</td>\n",
       "      <td>2.67</td>\n",
       "      <td>[Update, your, bathroom, with, the, Delta, Ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid             search_term  relevance  \\\n",
       "0   2       100001        [angle, bracket]       3.00   \n",
       "1   3       100001            [l, bracket]       2.50   \n",
       "2   9       100002            [deck, over]       3.00   \n",
       "3  16       100005    [rain, shower, head]       2.33   \n",
       "4  17       100005  [shower, only, faucet]       2.67   \n",
       "\n",
       "                                 product_description  \n",
       "0  [Not, only, do, angles, make, joints, stronger...  \n",
       "1  [Not, only, do, angles, make, joints, stronger...  \n",
       "2  [BEHR, Premium, Textured, DECKOVER, is, an, in...  \n",
       "3  [Update, your, bathroom, with, the, Delta, Ver...  \n",
       "4  [Update, your, bathroom, with, the, Delta, Ver...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_tokens(text):\n",
    "    text = text.replace(' ', ',')\n",
    "    text = text.replace('.', ',')\n",
    "    text = text.replace('\\n', ',')\n",
    "    text = text.replace(';', ',')\n",
    "    return text.split(',')\n",
    "\n",
    "def split_search_description(train, test):\n",
    "    train['search_term'] = [to_tokens(x) for x in train['search_term']]\n",
    "    test['search_term'] = [to_tokens(x) for x in test['search_term']]\n",
    "    train['product_description'] = [to_tokens(x) for x in train['product_description']]\n",
    "    test['product_description'] = [to_tokens(x) for x in test['product_description']]\n",
    "    return train, test\n",
    "\n",
    "train, test = load_data()\n",
    "train, test = split_search_description(train, test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_texts(train, test):\n",
    "    search_train = train['search_term'].to_numpy()\n",
    "    search_test = test['search_term'].to_numpy()\n",
    "    search_texts = np.concatenate([search_train,search_test])\n",
    "    des_train = train['product_description'].to_numpy()\n",
    "    des_test = test['product_description'].to_numpy()\n",
    "    des_texts = np.concatenate([des_train,des_test])\n",
    "    text = np.concatenate([search_texts,des_texts])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeber of diffrent words in the texts:  275997\n"
     ]
    }
   ],
   "source": [
    "def create_tokonizer_word(texts):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "train_word, test_word = load_data()\n",
    "text = create_texts(train_word, test_word)\n",
    "word_tk = create_tokonizer_word(text)\n",
    "print('numeber of diffrent words in the texts: ', len(word_tk.word_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_from_tk(train, test, search_tk, des_tk):\n",
    "    train['search_term'] = search_tk.texts_to_sequences(train['search_term'])\n",
    "    train['product_description'] = des_tk.texts_to_sequences(train['product_description'])\n",
    "    test['search_term'] = search_tk.texts_to_sequences(test['search_term'])\n",
    "    test['product_description'] = des_tk.texts_to_sequences(test['product_description'])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max_avg(A, B):\n",
    "    s_min = -1\n",
    "    s_max = -1\n",
    "    s_sum = 0\n",
    "    for a in A:\n",
    "        size = len(a)\n",
    "        s_sum += size\n",
    "        if s_min == -1 or s_min > size:\n",
    "            s_min = size\n",
    "        if s_max == -1 or s_max < size:\n",
    "            s_max = size\n",
    "    for b in B:\n",
    "        size = len(b)\n",
    "        s_sum += size\n",
    "        if s_min == -1 or s_min > size:\n",
    "            s_min = size\n",
    "        if s_max == -1 or s_max < size:\n",
    "            s_max = size\n",
    "    s_avg = int(s_sum / (len(A) + len(B)))\n",
    "    return s_min, s_max, s_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_with_padding(train, test, maxlen_search, maxlen_des):\n",
    "    X_train = train.copy().drop(['id','product_uid','relevance'], axis=1)\n",
    "    X_train['search_term'] = [x for x in pad_sequences(train['search_term'], maxlen=maxlen_search, padding='post')]\n",
    "    X_train['product_description'] = [x for x in pad_sequences(train['product_description'], maxlen=maxlen_des, padding='post')]\n",
    "    y_train = train.copy()['relevance']\n",
    "    \n",
    "    X_test = test.copy().drop(['id','product_uid','relevance'], axis=1)\n",
    "    X_test['search_term'] = [x for x in pad_sequences(test['search_term'], maxlen=maxlen_search, padding='post')]\n",
    "    X_test['product_description'] = [x for x in pad_sequences(test['product_description'], maxlen=maxlen_des, padding='post')]\n",
    "    y_test = test.copy()['relevance']\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    print('X train shape: ',X_train.shape, ' y train shape: ', y_train.shape)\n",
    "    print('X val shape: ',X_val.shape, ' y val shape: ', y_val.shape)\n",
    "    print('X test shape: ',X_test.shape, ' y test shape: ', y_test.shape)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector analyzes for product description: min= 1  ,max= 869  ,avg= 128\n",
      "vector analyzes for search term: min= 0  ,max= 13  ,avg= 2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['relevance'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mif\u001b[39;00m search_avg \u001b[39m>\u001b[39m des_avg:\n\u001b[0;32m     10\u001b[0m     maxlen_size \u001b[39m=\u001b[39m search_avg \n\u001b[1;32m---> 11\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test \u001b[39m=\u001b[39m create_X_y_with_padding(train, test, maxlen_size, maxlen_size)\n",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m, in \u001b[0;36mcreate_X_y_with_padding\u001b[1;34m(train, test, maxlen_search, maxlen_des)\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train[\u001b[39m'\u001b[39m\u001b[39mproduct_description\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m pad_sequences(train[\u001b[39m'\u001b[39m\u001b[39mproduct_description\u001b[39m\u001b[39m'\u001b[39m], maxlen\u001b[39m=\u001b[39mmaxlen_des, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      5\u001b[0m y_train \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mcopy()[\u001b[39m'\u001b[39m\u001b[39mrelevance\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m X_test \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39;49mcopy()\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mproduct_uid\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mrelevance\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m X_test[\u001b[39m'\u001b[39m\u001b[39msearch_term\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m pad_sequences(test[\u001b[39m'\u001b[39m\u001b[39msearch_term\u001b[39m\u001b[39m'\u001b[39m], maxlen\u001b[39m=\u001b[39mmaxlen_search, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      9\u001b[0m X_test[\u001b[39m'\u001b[39m\u001b[39mproduct_description\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m pad_sequences(test[\u001b[39m'\u001b[39m\u001b[39mproduct_description\u001b[39m\u001b[39m'\u001b[39m], maxlen\u001b[39m=\u001b[39mmaxlen_des, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[1;32mc:\\projects\\product-rec\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\projects\\product-rec\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\projects\\product-rec\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\product-rec\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['relevance'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train, test = train_test_from_tk(train, test, word_tk, word_tk)\n",
    "des_min, des_max, des_avg = find_min_max_avg(train['product_description'],test['product_description'])\n",
    "print('vector analyzes for product description: min=', des_min, ' ,max=',des_max, ' ,avg=', des_avg)\n",
    "\n",
    "search_min, search_max, search_avg = find_min_max_avg(train['search_term'],test['search_term'])\n",
    "print('vector analyzes for search term: min=', search_min, ' ,max=', search_max, ' ,avg=', search_avg)\n",
    "\n",
    "maxlen_size = des_avg\n",
    "if search_avg > des_avg:\n",
    "    maxlen_size = search_avg \n",
    "X_train, y_train, X_val, y_val, X_test, y_test = create_X_y_with_padding(train, test, maxlen_size, maxlen_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
